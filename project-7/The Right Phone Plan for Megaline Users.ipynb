{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Right Phone Plan for Megaline Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an analyst at Megaline, the job is to analyze behavior data about subscribers who have already switched to the new plans.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "Presented is an analysis of user behavior data that have switched from legacy plans to newer one. \n",
    "\n",
    "###  Goal:\n",
    "This report will focus on developing a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "The final model will have the highest possible accuracy. The threshold for accuracy is set at 0.75.\n",
    "\n",
    "\n",
    "### Stages:\n",
    "This project will consist of the following stages:\n",
    "\n",
    "1. Introduction\n",
    "2. General Information\n",
    "3. Split Dataset\n",
    "    1. Training\n",
    "    2. Validation\n",
    "    3. Test \n",
    "4. Model Testing\n",
    "    1. Decision Tree\n",
    "    2. Random Forest\n",
    "    3. Logistic Regression\n",
    "5. Quality Check\n",
    "6. Sanity Check\n",
    "7. Conclusion\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the file and study the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#import dataset\n",
    "\n",
    "users = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "#first five rows of the dataset\n",
    "print(users.head())\n",
    "\n",
    "#general info about the dataset\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains the following columns:\n",
    "- `сalls` — number of calls,\n",
    "- `minutes` — total call duration in minutes,\n",
    "- `messages` — number of text messages,\n",
    "- `mb_used` — Internet traffic used in MB,\n",
    "- `is_ultra` — plan for the current month (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to develope a model that predict/picks which of the newer plans (Smart or Ultra) is best for the customer based on their behavior. Since a test dataset is not present, we will split our dataset following a 3:1:1 ratio. Resulting a **training dataset**, **validation dataset**, and a **test dataset**. In addition, our features will be 'calls', 'minitues', 'messages', and 'mb_used'. The target will be 'is_ultra'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target and feature creation\n",
    "\n",
    "target = users['is_ultra']\n",
    "features = users.drop(['is_ultra'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create our target and features, it will make the splitting easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4) (643, 4) (643, 4)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset\n",
    "\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size = 0.4, random_state = 12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size = 0.5, random_state = 12345)\n",
    "\n",
    "print(features_train.shape,\n",
    "     features_valid.shape,\n",
    "     features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we have successfully split the dataset 3:1:1. features contain 4 columns because 'is_ultra' became the target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test 3 different models: Decision Tree, Random Forest, and the Logistic Regression. Since our target is categorical (0, 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to adjust the hyperparameter: max_depth to decide which will provide the best accuracy. Since we used random_state = 12345 on our dataset split, we will keep this hyperparameter the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth of 3 , Accuracy =  0.7853810264385692\n"
     ]
    }
   ],
   "source": [
    "#create a loop to test max_depth\n",
    "\n",
    "best_depth = 0\n",
    "accuracy = 0.75\n",
    "for depth in range (1,11):\n",
    "    tree_model = DecisionTreeClassifier(random_state = 12345, max_depth = depth)\n",
    "    tree_model.fit(features_train, target_train)\n",
    "    tree_prediction = tree_model.predict(features_valid)\n",
    "    tree_accuracy = accuracy_score(target_valid, tree_prediction)\n",
    "    if tree_accuracy > accuracy:\n",
    "            accuracy = tree_accuracy\n",
    "            best_depth = depth\n",
    "    \n",
    "print('Max depth of', best_depth, ',', 'Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model,the Decision Tree accuracy is between 75-78%. Within all of the max depth that we have tested, it appeared that **max depth = 3** has the best accuracy at 78.5%. We will use this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to adjust the hyperparameter: max_depth and n_estimators to decide which will provide the best accuracy. Since we used random_state = 12345 on our dataset split, we will keep this hyperparameter the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth of 8 and n_estimators of 40 Accuracy =  0.8087091757387247\n"
     ]
    }
   ],
   "source": [
    "#create a loop to test max_depth and n_estimators\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "accuracy = 0.75\n",
    "for depth in range (1,11):\n",
    "    for est in range (10, 101, 10):\n",
    "        forest_model = RandomForestClassifier(random_state = 12345, max_depth = depth, n_estimators = est)\n",
    "        forest_model.fit(features_train, target_train)\n",
    "        forest_prediction = forest_model.predict(features_valid)\n",
    "        forest_accuracy = accuracy_score(target_valid, forest_prediction)\n",
    "        if forest_accuracy > accuracy:\n",
    "            accuracy = forest_accuracy\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "print('Max depth of', best_depth, 'and n_estimators of', best_est, 'Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our result suggested that using a **max_depth of 8 and n_estimator of 40** will grant a 80.87% accuracy, which is higher than the highest accuracy Decision Tree achieved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do for Logistic Regression is set a solver, we will use the default. and keep the random_state the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Logistic Regression is: 0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logistic_model = LogisticRegression(random_state = 12345)\n",
    "logistic_model.fit(features_train, target_train)\n",
    "logistic_prediction = logistic_model.predict(features_valid)\n",
    "print('Accuracy for Logistic Regression is:', accuracy_score(target_valid, logistic_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy from logistic regression is 71.1%. Which appeared to be lower that both randomforest and decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing three models, we found that logistic regression model is the fastest, but with the lowest accuracy. Decision tree ranks 2nd in both accuracy and speed. While Randomforest is the most accurate but also the most time-consuming. Since our goal is to have a model with the highest accuracy, we will use **RandomForest** with hyperparameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for our model using test dataset is: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "#Quality check with test_dataset\n",
    "\n",
    "model = RandomForestClassifier(random_state = 12345, n_estimators = 40, max_depth = 8)\n",
    "model.fit(features_train, target_train)\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "print('The accuracy for our model using test dataset is:', accuracy_score(target_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RandomForest model gave a 79.6% accuracy, which is higher than our accuracy threshold set at 75%. Therefore our model has passed the quality check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preform a sanity check, making sure our model is performing better than chance. We will use DummyClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for dummy model using test dataset is: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "#Quality check with test_dataset\n",
    "\n",
    "dummy_model = DummyClassifier(random_state = 12345)\n",
    "dummy_model.fit(features_train, target_train)\n",
    "dummy_prediction = dummy_model.predict(features_test)\n",
    "\n",
    "print('The accuracy for dummy model using test dataset is:', accuracy_score(target_test, dummy_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummymodel would have an accuracy of 68.4%, which is less than our model. It indicates that our model has passed the sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully developed a model that will predict which of the new plans is best for a customer based on their phone usage behavior. We first split our data following a 3:1:1 ratio into training, validation and test sets. And then test three models and determined that RandomForest with n_estimators = 40 and max_depth = 8 returned the highest accuracy. This model was used to test test sets and resulted in a ~80% accuracy and it is higher than the dummy model, therefore passing the quality and sanity check."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 937,
    "start_time": "2022-06-14T13:43:23.709Z"
   },
   {
    "duration": 81,
    "start_time": "2022-06-14T13:45:07.062Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-14T13:45:16.204Z"
   },
   {
    "duration": 83,
    "start_time": "2022-06-14T13:52:55.869Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-14T13:53:10.620Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-14T13:59:54.369Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-14T14:00:08.016Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-14T14:00:52.173Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-14T14:11:04.101Z"
   },
   {
    "duration": 66,
    "start_time": "2022-06-14T14:11:14.994Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-14T14:18:21.949Z"
   },
   {
    "duration": 11307,
    "start_time": "2022-06-14T14:18:37.493Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-14T14:24:48.635Z"
   },
   {
    "duration": 11622,
    "start_time": "2022-06-14T14:24:55.599Z"
   },
   {
    "duration": 11376,
    "start_time": "2022-06-14T14:26:35.822Z"
   },
   {
    "duration": 11256,
    "start_time": "2022-06-14T14:27:30.666Z"
   },
   {
    "duration": 11069,
    "start_time": "2022-06-14T14:28:44.132Z"
   },
   {
    "duration": 11116,
    "start_time": "2022-06-14T14:29:49.137Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-14T14:37:20.679Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-14T14:38:09.518Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-14T14:39:16.193Z"
   },
   {
    "duration": 47,
    "start_time": "2022-06-14T14:39:16.197Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-14T14:39:16.245Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-14T14:39:16.250Z"
   },
   {
    "duration": 62,
    "start_time": "2022-06-14T14:39:16.259Z"
   },
   {
    "duration": 11550,
    "start_time": "2022-06-14T14:39:16.322Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-14T14:39:27.874Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-14T14:39:55.361Z"
   },
   {
    "duration": 29,
    "start_time": "2022-06-14T14:40:14.236Z"
   },
   {
    "duration": 58,
    "start_time": "2022-06-14T14:41:34.586Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-14T14:43:13.192Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-14T14:43:26.165Z"
   },
   {
    "duration": 104,
    "start_time": "2022-06-14T14:59:21.876Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-14T15:32:18.738Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-14T15:36:02.640Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-14T15:36:43.937Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
