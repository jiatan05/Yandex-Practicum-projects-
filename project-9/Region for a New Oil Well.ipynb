{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region for a New Oil Well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an analyst at OilyGiant mining company, the job is to analyze oil reserve data in three different regions and their profit margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "Presented is an analysis of oil reserve data that based on the region and their profit margin. \n",
    "\n",
    "###  Goal:\n",
    "This report will focus on developing a Linear Regression model that would predict which region is most suitable for a new oil well (the one with the highest profit margin). Each region will be used to train a separate model to cauclate how much oil it has, and the reveune. \n",
    "The end goal is to pick the region with the highest profit margin.\n",
    "\n",
    "\n",
    "### Stages:\n",
    "This project will consist of the following stages:\n",
    "\n",
    "1. Introduction\n",
    "2. General Information\n",
    "3. Split Dataset\n",
    "    1. Training\n",
    "    2. Validation\n",
    "4. Model Traning\n",
    "    1. Region 1\n",
    "    2. Region 2\n",
    "    3. Region 3\n",
    "5. Profit Pre-determination\n",
    "6. Profit and Risk\n",
    "    1. Region 1\n",
    "    2. Region 2\n",
    "    3. Region 3\n",
    "7.  Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.random import RandomState\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's open all of our datasets and study them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets\n",
    "\n",
    "region_1 = pd.read_csv('/datasets/geo_data_0.csv')\n",
    "region_2 = pd.read_csv('/datasets/geo_data_1.csv')\n",
    "region_3 = pd.read_csv('/datasets/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#take a look of region 1\n",
    "\n",
    "print(region_1.head())\n",
    "region_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#region 2\n",
    "\n",
    "print(region_2.head())\n",
    "region_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#region 3\n",
    "\n",
    "print(region_3.head())\n",
    "region_3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets consist of the following columns:\n",
    "- `d` — unique oil well identifier\n",
    "- `f0, f1, f2` — three features of points \n",
    "- `product` — volume of reserves in the oil well (thousand barrels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the datasets infomation, it appears that there are no missing information. The target will be the **'product'** column.\n",
    "\n",
    "However, we will need to remove the columns that do not contribute to our model, in this case, it will the 'id' column. \n",
    "\n",
    "The remaining columns will be features. \n",
    "\n",
    "We will also need to split our data into training and validation sets with a 75:25 ratio. \n",
    "\n",
    "Finally, we will need to standardize numerical columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are spliting the datasets all the same ways, we can create a function to do so for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function for spliting datasets into training and validation sets\n",
    "\n",
    "def splitdata(dataset):\n",
    "    #dropping unnecessary column\n",
    "    dataset = dataset.drop(['id'], axis = 1)\n",
    "    \n",
    "    #set features and target\n",
    "    features = dataset.drop(['product'], axis = 1)\n",
    "    target = dataset['product']\n",
    "    \n",
    "    #now split\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "    #then standardize the numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    numerical = ['f0', 'f1', 'f2']\n",
    "    \n",
    "    scaler.fit(features_train[numerical])\n",
    "    \n",
    "    features_train[numerical] = scaler.transform(features_train[numerical])\n",
    "    features_valid[numerical] = scaler.transform(features_valid[numerical])\n",
    "    \n",
    "    #return features and target for both sets\n",
    "    \n",
    "    return features_train, features_valid, target_train, target_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3) (25000, 3)\n",
      "             f0        f1        f2\n",
      "27212 -0.544828  1.390264 -0.094959\n",
      "7866   1.455912 -0.480422  1.209567\n",
      "62041  0.260460  0.825069 -0.204865\n",
      "70185 -1.837105  0.010321 -0.147634\n",
      "82230 -1.299243  0.987558  1.273181\n",
      "(75000, 3) (25000, 3)\n",
      "             f0        f1        f2\n",
      "27212 -0.850855  0.624428  0.296943\n",
      "7866   1.971935  1.832275  0.294333\n",
      "62041  1.079305  0.170127 -0.296418\n",
      "70185 -1.512028 -0.887837 -0.880471\n",
      "82230 -1.804775 -0.718311 -0.293255\n",
      "(75000, 3) (25000, 3)\n",
      "             f0        f1        f2\n",
      "27212 -0.526160  0.776329 -0.400793\n",
      "7866  -0.889625 -0.404070 -1.222936\n",
      "62041 -1.133984  0.208576  0.296765\n",
      "70185  1.227045  1.570166 -0.764556\n",
      "82230 -0.194289  0.878312  0.840821\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Now apply the function to all three datasets\n",
    "\n",
    "r1_features_train, r1_features_valid, r1_target_train, r1_target_valid = splitdata(region_1)\n",
    "\n",
    "r2_features_train, r2_features_valid, r2_target_train, r2_target_valid = splitdata(region_2)\n",
    "\n",
    "r3_features_train, r3_features_valid, r3_target_train, r3_target_valid = splitdata(region_3)\n",
    "\n",
    "#to check\n",
    "\n",
    "print(r1_features_train.shape,\n",
    "     r1_features_valid.shape)\n",
    "print(r1_features_train.head())\n",
    "print(r2_features_train.shape,\n",
    "     r2_features_valid.shape)\n",
    "print(r2_features_train.head())\n",
    "print(r3_features_train.shape,\n",
    "     r3_features_valid.shape)\n",
    "print(r3_features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully split and standardized the all of the sets, we will train and test the Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like spliting the dataset: we are doing the same thing for all datasets, so we will create a function for easier process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function\n",
    "\n",
    "def model_pred(features_train, features_valid, target_train, target_valid):\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    \n",
    "    RMSE = mean_squared_error(target_valid, predicted_valid)**0.5\n",
    "    \n",
    "    return RMSE, predicted_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 1 RMSE: 37.5794217150813 Region 1 average volume of predicted reserves: 92.59256778438035\n",
      "Region 2 RMSE: 0.893099286775617 Region 2 average volume of predicted reserves: 68.728546895446\n",
      "Region 3 RMSE: 40.02970873393434 Region 3 average volume of predicted reserves: 94.96504596800489\n"
     ]
    }
   ],
   "source": [
    "#applying the function\n",
    "\n",
    "RMSE1, predicted_valid_r1 = model_pred(r1_features_train, r1_features_valid, r1_target_train, r1_target_valid)\n",
    "RMSE2, predicted_valid_r2 = model_pred(r2_features_train, r2_features_valid, r2_target_train, r2_target_valid)\n",
    "RMSE3, predicted_valid_r3 = model_pred(r3_features_train, r3_features_valid, r3_target_train, r3_target_valid)\n",
    "\n",
    "\n",
    "print('Region 1 RMSE:', RMSE1, 'Region 1 average volume of predicted reserves:', predicted_valid_r1.mean())\n",
    "print('Region 2 RMSE:', RMSE2, 'Region 2 average volume of predicted reserves:', predicted_valid_r2.mean())\n",
    "print('Region 3 RMSE:', RMSE3, 'Region 3 average volume of predicted reserves:', predicted_valid_r3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model, the region with the highest average volume of reserves region 3, follow closely by region 2 (94.96 and 92.59, respectively). However, region 2 has the by far the lowest RMSE meaning that the potential for lower profit than expected is low (+/- 0.89 units) while region 1 is (+/-37.57), region 3 (+/- 40.03). We will look into the data more to determine which is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profit Pre-Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the company:\n",
    "\n",
    "- The budget for development of 200 oil wells is 100 USD million.\n",
    "\n",
    "- A study of 500 points is carried out with picking the best 200 points for profit calculation\n",
    "\n",
    "- One barrel of raw materials brings 4.5 USD of revenue. While the revenue from one unit of product is 4,500 dollars(volume of reserves is in thousand barrels)\n",
    "\n",
    "\n",
    "All things consider, we will need to calculate the volume of reserve needed for a new well without suffering a loss in profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of reserve needed for a new well without a loss: 111.11111111111111\n"
     ]
    }
   ],
   "source": [
    "#calculation\n",
    "\n",
    "wells = 200\n",
    "budget = 100000000\n",
    "profit_per_volume = 4500\n",
    "\n",
    "budget_per_well = budget / wells\n",
    "\n",
    "product_revenue = budget_per_well / profit_per_volume\n",
    "\n",
    "print('Volume of reserve needed for a new well without a loss:', product_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation suggested that the minium volume of reserve needed for a new well that will turn a profit is 111.11. Which none of the regions met in the first rounds of model training. \n",
    "\n",
    "Ideally, we will need to choose locations with the volume of predicted reserves is greater than the average of its region. We will do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk and Profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the predicted profit for the top 200 wells in each region(dataset). We will be using the bootstrapping techniques to create subsamples (1000) to caculate this. Since we are repeating the operation, we will write a function to save time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 1:\n",
      "Average Profit: $3961649.8480237117 USD\n",
      "95% confidence interval for average profit is: (-1112155.4589049604, 9097669.41553423)\n",
      "Risk of loss: 6.900000%\n",
      "\n",
      "Region 2:\n",
      "Average Profit: $4560451.057866608 USD\n",
      "95% confidence interval for average profit is: (338205.0939898458, 8522894.538660347)\n",
      "Risk of loss: 1.500000%\n",
      "\n",
      "Region 3:\n",
      "Average Profit: $4044038.665683568 USD\n",
      "95% confidence interval for average profit is: (-1633504.1339559986, 9503595.749237997)\n",
      "Risk of loss: 7.600000%\n"
     ]
    }
   ],
   "source": [
    "#write two functions: 1 for revenue of the top 200 wells at region\n",
    "def revenue(target, predicted, n):\n",
    "    predicted = pd.Series(predicted)\n",
    "    target = target.reset_index(drop = True)\n",
    "    index = predicted.sort_values(ascending = False).index\n",
    "    return (target.loc[index][:200].sum() * profit_per_volume) - budget\n",
    "\n",
    "#write the function for calculating average profit with 200 wells. \n",
    "\n",
    "def rev_calc(target, predictions):\n",
    "    state = RandomState(12345)\n",
    "    values = []\n",
    "    target = target.reset_index(drop=True)\n",
    "    \n",
    "    #bootstrapping\n",
    "    for i in range(1000):\n",
    "        target_sample = target.sample(n=500,replace = True, random_state = state)\n",
    "        predictions_sample = predictions[target_sample.index]\n",
    "        values.append(revenue(target_sample, predictions_sample, wells))\n",
    "        \n",
    "    \n",
    "    values = pd.Series(values)\n",
    "    \n",
    "    mean = values.mean()\n",
    "    lower = values.quantile(0.025)\n",
    "    upper = values.quantile(0.975)\n",
    "    loss_risk = len(values[values < 0] / len(values)) / 1000\n",
    "    \n",
    "    print('Average Profit: ${} USD'.format(mean))\n",
    "    print('95% confidence interval for average profit is: ({}, {})'.format(lower, upper))\n",
    "    print('Risk of loss: {0:0%}'.format(loss_risk))\n",
    "    \n",
    "print('Region 1:')\n",
    "rev_calc(r1_target_valid, predicted_valid_r1)\n",
    "\n",
    "print('\\nRegion 2:')\n",
    "rev_calc(r2_target_valid, predicted_valid_r2)\n",
    "\n",
    "print('\\nRegion 3:')\n",
    "rev_calc(r3_target_valid, predicted_valid_r3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our model calculation, Region 2 appeared to be the region that will bring the most profit margin. With a risk of loss at 1.5%, average profit = $4560451.057866608 USD, and the 95% confidence interval limits being (338205.0939898458, 8522894.538660347). Other regions have a higher risk of loss, and confidence interval range between negative (loss). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion:\n",
    "\n",
    "We have trained Linear Regression model for all three regions. We have calculated the units of volumes needed to not suffer a loss. We then bootstrapped the target values with 500 samples(amounts of points carried out) and calculated profit values for the top 200 wells.\n",
    "\n",
    "The boostrapping step suggested that Region 2 appeared to be the region is most likely to be profitable and with the biggest profit margin. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1478,
    "start_time": "2022-07-12T15:58:34.984Z"
   },
   {
    "duration": 726,
    "start_time": "2022-07-12T16:02:35.396Z"
   },
   {
    "duration": 15,
    "start_time": "2022-07-12T16:03:09.950Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-12T16:04:22.067Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-12T16:04:46.968Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-12T16:05:05.742Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-12T18:10:37.282Z"
   },
   {
    "duration": 197,
    "start_time": "2022-07-12T18:14:24.359Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-12T18:15:06.801Z"
   },
   {
    "duration": 118,
    "start_time": "2022-07-12T18:15:09.170Z"
   },
   {
    "duration": 83,
    "start_time": "2022-07-12T18:15:33.171Z"
   },
   {
    "duration": 22,
    "start_time": "2022-07-12T18:16:16.826Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-12T18:16:31.147Z"
   },
   {
    "duration": 98,
    "start_time": "2022-07-12T18:16:34.520Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-12T18:25:06.265Z"
   },
   {
    "duration": 49,
    "start_time": "2022-07-12T18:28:07.176Z"
   },
   {
    "duration": 139,
    "start_time": "2022-07-12T18:29:42.906Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-12T18:43:21.083Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-12T18:55:19.599Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-12T19:52:56.695Z"
   },
   {
    "duration": 24,
    "start_time": "2022-07-12T19:53:07.367Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-12T19:53:16.338Z"
   },
   {
    "duration": 15,
    "start_time": "2022-07-12T19:54:27.765Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-12T19:54:40.501Z"
   },
   {
    "duration": 20,
    "start_time": "2022-07-12T19:55:53.750Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-12T19:57:51.544Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-12T19:58:00.159Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-12T19:58:18.477Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-12T19:59:03.116Z"
   },
   {
    "duration": 26,
    "start_time": "2022-07-12T20:01:40.988Z"
   },
   {
    "duration": 2557,
    "start_time": "2022-07-12T20:07:37.712Z"
   },
   {
    "duration": 2543,
    "start_time": "2022-07-12T20:10:40.471Z"
   },
   {
    "duration": 2720,
    "start_time": "2022-07-12T20:12:14.237Z"
   },
   {
    "duration": 2543,
    "start_time": "2022-07-12T20:14:51.593Z"
   },
   {
    "duration": 24,
    "start_time": "2022-07-12T20:15:38.010Z"
   },
   {
    "duration": 2449,
    "start_time": "2022-07-12T20:15:46.700Z"
   },
   {
    "duration": 2577,
    "start_time": "2022-07-12T20:24:15.035Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
